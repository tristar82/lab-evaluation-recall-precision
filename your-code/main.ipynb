{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 36000th digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27211b80400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot\n",
    "X[36000].reshape(28,28)\n",
    "\n",
    "plt.pyplot.imshow(X[36000].reshape(28,28), cmap = plt.cm.binary , interpolation=\"nearest\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 36000th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#X_train, X_test, y_train,  y_test = train_test_split(website_dummy_x, website_dummy_y, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train = X[0:60000]\n",
    "y_train = y[0:60000] \n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "y_train_bin = np.where(y_train=='5',1,0)\n",
    "y_test_bin = np.where(y_test=='5',1,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellio\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "y_train_model = LogisticRegression(random_state=0).fit(X_train, y_train_bin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y_train_model.predict(X[36000].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "#Yes it did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 35th value is a 5. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "y_train_model.predict(X[35].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_train_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "#Yes it did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "never_5_clf.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "[[9027   81]\n",
      " [ 145  747]]\n",
      "0.9021739130434783\n",
      "0.8374439461883408\n",
      "0.8686046511627907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellio\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ellio\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "dumb_pred = never_5_clf.predict(X_test)\n",
    "dumb_pred\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, auc\n",
    "\n",
    "confusio = confusion_matrix(y_test_bin, dumb_pred)\n",
    "print(confusio)\n",
    "precision = precision_score(y_test_bin, dumb_pred)\n",
    "recall = recall_score(y_test_bin, dumb_pred)\n",
    "f1_score1 = f1_score(y_test_bin, dumb_pred)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score1)\n",
    "\n",
    "confusio = confusion_matrix(y_test_bin, y_pred)\n",
    "print(confusio)\n",
    "precision = precision_score(y_test_bin, y_pred)\n",
    "print(precision)\n",
    "recall = recall_score(y_test_bin, y_pred)\n",
    "print(recall)\n",
    "f1_score2 = f1_score(y_test_bin, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(f1_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "#all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y = y_test_bin\n",
    "scores = X_test\n",
    "variable = y_train_model.predict_proba(X_test)[:,1]\n",
    "#variable\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_bin, variable) #2nd element is asking for\n",
    "#fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "#import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747261806995673\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
